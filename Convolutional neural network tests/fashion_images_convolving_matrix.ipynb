{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer conv2d_1 weight shape (3, 3, 1, 32) is not compatible with provided weight shape (3, 3, 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 42\u001b[0m\n\u001b[1;32m     37\u001b[0m conv3_weights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m-\u001b[39m\u001b[39m0.06434292\u001b[39m, \u001b[39m0.0027218\u001b[39m, \u001b[39m0.03400089\u001b[39m],\n\u001b[1;32m     38\u001b[0m                           [ \u001b[39m0.04825743\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.04293629\u001b[39m, \u001b[39m0.01090491\u001b[39m],\n\u001b[1;32m     39\u001b[0m                           [\u001b[39m-\u001b[39m\u001b[39m0.03814485\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.07395639\u001b[39m, \u001b[39m0.07413089\u001b[39m]])\n\u001b[1;32m     41\u001b[0m \u001b[39m# Set the weights for each layer\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m model\u001b[39m.\u001b[39;49mget_layer(\u001b[39m\"\u001b[39;49m\u001b[39mconv2d_1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mset_weights([np\u001b[39m.\u001b[39;49mexpand_dims(conv1_weights, axis\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m), np\u001b[39m.\u001b[39;49mzeros(\u001b[39m32\u001b[39;49m)])\n\u001b[1;32m     43\u001b[0m model\u001b[39m.\u001b[39mget_layer(\u001b[39m\"\u001b[39m\u001b[39mconv2d_2\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mset_weights([np\u001b[39m.\u001b[39mexpand_dims(conv2_weights, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m), np\u001b[39m.\u001b[39mzeros(\u001b[39m32\u001b[39m)])\n\u001b[1;32m     44\u001b[0m model\u001b[39m.\u001b[39mget_layer(\u001b[39m\"\u001b[39m\u001b[39mconv2d_3\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mset_weights([np\u001b[39m.\u001b[39mexpand_dims(conv3_weights, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m), np\u001b[39m.\u001b[39mzeros(\u001b[39m32\u001b[39m)])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/engine/base_layer.py:1643\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1641\u001b[0m ref_shape \u001b[39m=\u001b[39m param\u001b[39m.\u001b[39mshape\n\u001b[1;32m   1642\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ref_shape\u001b[39m.\u001b[39mis_compatible_with(weight_shape):\n\u001b[0;32m-> 1643\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1644\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m weight shape \u001b[39m\u001b[39m{\u001b[39;00mref_shape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1645\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mis not compatible with provided weight \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1646\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mweight_shape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1647\u001b[0m weight_value_tuples\u001b[39m.\u001b[39mappend((param, weight))\n\u001b[1;32m   1648\u001b[0m weight_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer conv2d_1 weight shape (3, 3, 1, 32) is not compatible with provided weight shape (3, 3, 1)."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv2d_1'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), name='max_pooling2d_1'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', name='conv2d_2'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), name='max_pooling2d_2'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', name='conv2d_3'),\n",
    "    tf.keras.layers.Flatten(name='flatten'),\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='dense_1'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "])\n",
    "import numpy as np\n",
    "\n",
    "# Define the weight matrices for each convolutional layer\n",
    "import numpy as np\n",
    "\n",
    "# Specify the weights for each layer\n",
    "conv1_weights = np.array([[ 0.02194263, 0.24223748, 0.6781008 ],\n",
    "                          [ 0.4244324, -2.0073264, 1.1214318 ],\n",
    "                          [ 1.2498991, -0.39772153, -0.804002 ]])\n",
    "conv2_weights = np.array([[-0.07837418, 0.05449237, -0.19679523],\n",
    "                          [-0.02561542, 0.04406982, -0.02470637],\n",
    "                          [ 0.03877447, 0.06037814, -0.03606384]])\n",
    "conv3_weights = np.array([[-0.06434292, 0.0027218, 0.03400089],\n",
    "                          [ 0.04825743, -0.04293629, 0.01090491],\n",
    "                          [-0.03814485, -0.07395639, 0.07413089]])\n",
    "\n",
    "# Set the weights for each layer\n",
    "model.get_layer(\"conv2d_1\").set_weights([np.expand_dims(conv1_weights, axis=2), np.zeros(32)])\n",
    "model.get_layer(\"conv2d_2\").set_weights([np.expand_dims(conv2_weights, axis=2), np.zeros(32)])\n",
    "model.get_layer(\"conv2d_3\").set_weights([np.expand_dims(conv3_weights, axis=2), np.zeros(32)])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Print the initial filter matrix\n",
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        filters = layer.get_weights()[0]\n",
    "        print(f\"Convolutional matrix of layer {layer.name}:\" )\n",
    "        print(filters[:,:,0,0])\n",
    "\n",
    "# Define a function to display the convolutional filters as matrices of numbers\n",
    "def display_convolutional_filters(layer_name):\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    weights = layer.get_weights()[0]\n",
    "    fig, axs = plt.subplots(nrows=4, ncols=8, figsize=(10, 5))\n",
    "    fig.suptitle(layer_name)\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            axs[i][j].imshow(weights[:, :, 0, i * 8 + j], cmap='gray')\n",
    "            axs[i][j].axis('off')\n",
    "            axs[i][j].set_xticklabels([])\n",
    "            axs[i][j].set_yticklabels([])\n",
    "\n",
    "# Display the convolutional filters before training\n",
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        display_convolutional_filters(layer.name)\n",
    "plt.show()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=3, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Display the convolutional filters after training\n",
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        display_convolutional_filters(layer.name)\n",
    "plt.show()\n",
    "# Print the initial filter matrix\n",
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        filters = layer.get_weights()[0]\n",
    "        print(f\"Convolutional matrix of layer {layer.name}:\" )\n",
    "        print(filters[:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'activation')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_output_shape\u001b[39m(\u001b[39mself\u001b[39m, input_shape):\n\u001b[1;32m     20\u001b[0m         \u001b[39mreturn\u001b[39;00m (input_shape[\u001b[39m0\u001b[39m], input_shape[\u001b[39m1\u001b[39m], input_shape[\u001b[39m2\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters)\n\u001b[1;32m     23\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m---> 24\u001b[0m     MyConv2D(\u001b[39m32\u001b[39;49m, \u001b[39m3\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m28\u001b[39;49m, \u001b[39m28\u001b[39;49m, \u001b[39m1\u001b[39;49m), name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmy_conv2d_1\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     25\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mMaxPooling2D((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax_pooling2d_1\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     26\u001b[0m     MyConv2D(\u001b[39m64\u001b[39m, \u001b[39m3\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmy_conv2d_2\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     27\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mMaxPooling2D((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax_pooling2d_2\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     28\u001b[0m     MyConv2D(\u001b[39m128\u001b[39m, \u001b[39m3\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmy_conv2d_3\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     29\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mflatten\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     30\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m128\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdense_1\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     31\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m10\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m ])\n",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m, in \u001b[0;36mMyConv2D.__init__\u001b[0;34m(self, filters, kernel_size, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filters, kernel_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m----> 3\u001b[0m     \u001b[39msuper\u001b[39;49m(MyConv2D, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters \u001b[39m=\u001b[39m filters\n\u001b[1;32m      5\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size \u001b[39m=\u001b[39m kernel_size\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/engine/base_layer.py:332\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m allowed_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    322\u001b[0m     \u001b[39m'\u001b[39m\u001b[39minput_dim\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    323\u001b[0m     \u001b[39m'\u001b[39m\u001b[39minput_shape\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mimplementation\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    330\u001b[0m }\n\u001b[1;32m    331\u001b[0m \u001b[39m# Validate optional keyword arguments.\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m generic_utils\u001b[39m.\u001b[39;49mvalidate_kwargs(kwargs, allowed_kwargs)\n\u001b[1;32m    334\u001b[0m \u001b[39m# Mutable properties\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[39m# Indicates whether the layer's weights are updated during training\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[39m# and whether the layer's updates are run during training.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(trainable, \u001b[39mbool\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m    338\u001b[0m         (\u001b[39misinstance\u001b[39m(trainable, (tf\u001b[39m.\u001b[39mTensor, tf\u001b[39m.\u001b[39mVariable)) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    339\u001b[0m          trainable\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m tf\u001b[39m.\u001b[39mbool)):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/generic_utils.py:1174\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[39mfor\u001b[39;00m kwarg \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m   1173\u001b[0m   \u001b[39mif\u001b[39;00m kwarg \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_kwargs:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(error_message, kwarg)\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'activation')"
     ]
    }
   ],
   "source": [
    "class MyConv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super(MyConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(self.kernel_size, self.kernel_size, input_shape[-1], self.filters),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyConv2D, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        outputs = tf.nn.conv2d(inputs, self.kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        outputs = tf.nn.relu(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], input_shape[2], self.filters)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    MyConv2D(32, 3, activation='relu', input_shape=(28, 28, 1), name='my_conv2d_1'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), name='max_pooling2d_1'),\n",
    "    MyConv2D(64, 3, activation='relu', name='my_conv2d_2'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), name='max_pooling2d_2'),\n",
    "    MyConv2D(128, 3, activation='relu', name='my_conv2d_3'),\n",
    "    tf.keras.layers.Flatten(name='flatten'),\n",
    "    tf.keras.layers.Dense(128, activation='relu', name='dense_1'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
