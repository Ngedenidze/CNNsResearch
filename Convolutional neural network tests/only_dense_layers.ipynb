{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b367fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gedena/miniconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 08:17:47.273076: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-03 08:17:47.273702: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m\n\u001b[1;32m     22\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, digits\u001b[39m.\u001b[39mtarget, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39m# Define the model\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m# model = tf.keras.models.Sequential([\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m#     tf.keras.layers.Dense(128, activation='relu', input_shape=(64,)),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m#     tf.keras.layers.Dense(10, activation='softmax')\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# ])\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mSequential([\n\u001b[1;32m     33\u001b[0m     layers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m32\u001b[39;49m, (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m64\u001b[39;49m,)),\n\u001b[1;32m     34\u001b[0m     layers\u001b[39m.\u001b[39;49mMaxPooling2D((\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m)),\n\u001b[1;32m     35\u001b[0m     layers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m32\u001b[39;49m, (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     36\u001b[0m     layers\u001b[39m.\u001b[39;49mMaxPooling2D((\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m)),\n\u001b[1;32m     37\u001b[0m     layers\u001b[39m.\u001b[39;49mFlatten(),\n\u001b[1;32m     38\u001b[0m     layers\u001b[39m.\u001b[39;49mDense(\u001b[39m10\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     39\u001b[0m     layers\u001b[39m.\u001b[39;49mDense(\u001b[39m10\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msoftmax\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     40\u001b[0m ])\n\u001b[1;32m     42\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n\u001b[1;32m     43\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/engine/input_spec.py:228\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    226\u001b[0m   ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    227\u001b[0m   \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    230\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    231\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    232\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 64)"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler, Binarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(digits.data)\n",
    "\n",
    "# Binarize the data\n",
    "binarizer = Binarizer(threshold=0.0)\n",
    "X = binarizer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, digits.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(128, activation='relu', input_shape=(64,)),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64,)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "start_time = time.time()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "end_time = time.time()\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2424596e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,386\n",
      "Trainable params: 21,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e67bcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed during training: 4.98 seconds\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1797 - accuracy: 0.9444\n",
      "Test accuracy: 0.944444477558136\n"
     ]
    }
   ],
   "source": [
    "total_time = end_time - start_time\n",
    "print(f'Total time elapsed during training: {total_time:.2f} seconds')\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce09768e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24/45 [===============>..............] - ETA: 0s - loss: 1.9697 - accuracy: 0.3398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 08:18:53.903948: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 5ms/step - loss: 1.5440 - accuracy: 0.5546\n",
      "Epoch 2/5\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.9054\n",
      "Epoch 3/5\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.9388\n",
      "Epoch 4/5\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.2184 - accuracy: 0.9645\n",
      "Epoch 5/5\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.9722\n",
      "Test loss: 0.1624, Test accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 08:18:54.993722: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#binirize after building the architecture\n",
    "# Load the dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(digits.data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, digits.target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(64,)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "start_time = time.time()\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "end_time = time.time()\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff77657f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed during training: 1.18 seconds\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1624 - accuracy: 0.9667\n",
      "Test accuracy: 0.9666666984558105\n"
     ]
    }
   ],
   "source": [
    "total_time = end_time - start_time\n",
    "print(f'Total time elapsed during training: {total_time:.2f} seconds')\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8e3161",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_digits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m digits \u001b[39m=\u001b[39m load_digits()\n\u001b[1;32m      3\u001b[0m \u001b[39m# Scale the data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_digits' is not defined"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(digits.data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, digits.target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.Lambda(lambda x: tf.where(x >= 0, 1, -1)), # add binarization layer\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (5, 5), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a7a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
