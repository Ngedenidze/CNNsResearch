{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956c8474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gedena/miniconda3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nltk\n",
    "from transformers import TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87762df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 15:35:40.645583: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-17 15:35:40.645605: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94668760/94668760 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88aa727433d7434ba3d23096d5cc582a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837860079c90411baddf93ba6cc759f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"tf_model.h5\";:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained CNN for image feature extraction\n",
    "cnn = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet')\n",
    "\n",
    "# Load pre-trained NLP model for question feature extraction\n",
    "nlp_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define rules and logical statements for symbolic reasoning\n",
    "# For example:\n",
    "def rule1(image_features, question_features):\n",
    "    if np.mean(image_features) > np.mean(question_features):\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        return \"no\"\n",
    "\n",
    "# Define decision-making module\n",
    "# For example:\n",
    "def decision_module(candidates):\n",
    "    return max(candidates, key=candidates.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e9665fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_images() missing 1 required positional argument: 'filepaths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load dataset and preprocess data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# For example:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m image_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m question_data \u001b[38;5;241m=\u001b[39m load_questions()\n\u001b[1;32m      5\u001b[0m answer_data \u001b[38;5;241m=\u001b[39m load_answers()\n",
      "\u001b[0;31mTypeError\u001b[0m: load_images() missing 1 required positional argument: 'filepaths'"
     ]
    }
   ],
   "source": [
    "# Load dataset and preprocess data\n",
    "# For example:\n",
    "image_data = load_images()\n",
    "question_data = load_questions()\n",
    "answer_data = load_answers()\n",
    "image_features = cnn.predict(image_data)\n",
    "question_features = nlp_model.predict(question_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5976b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_images(filepaths):\n",
    "    images = []\n",
    "    for filepath in filepaths:\n",
    "        image = Image.open(filepath)\n",
    "        images.append(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4aaaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
